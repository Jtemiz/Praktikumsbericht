%% Dokumenteinstellungen
\documentclass[
    type=Projektarbeit,
    status=draft, % Ändern zu "final" für die Abgabeversion
    language=german, % oder: "english"
    bibengine=bibtex,
]{unibwm-inf-thesis}

\usepackage{textcomp}
\usepackage{verbatim}
\usepackage{listings}
\bibliographystyle{apalike-german}
\usepackage{url}
\newcommand{\todo}[1]{\textbf{TODO: #1}}
\setvalue{title}{Qualitätssicherung im Schaltanlagenbau: Konzeption und Implementierung DPP}
\setvalue{author}{Joel Temiz}
\setvalue{matrnr}{1196670}

\setvalue{examiner}{Prof. Dr. Ulrike Lechner}
\setvalue{advisor}{Hpmt Lisa Verlande}
\setvalue{advisorlabel}{Betreuerin}
\setvalue{seminartitle}{Praxisprojekt}
\setvalue{seminarcontext}{Sommertrimester 2022}
\setvalue{deadline}{30.09.2022}
\usepackage{amsmath}
\usepackage{nameref}
\usepackage[printonlyused]{acronym}
\begin{document}
    \tableofcontents

    \mainmatter
    \begin{abstract}
        abstract
    \end{abstract}


    \chapter{Einleitung und Motivation}


    \chapter{Gesamtkonzept von DPP und Einordnung in Fertigungsprozess}
    Zur Umsetzung eines betrieblichen Anwendungssystems muss im ersten Schritt eine Konzeption erfolgen, die darstellt,
    wie die Anwendung gestaltet sein kann, um das gewünschte Ziel zu erfüllen.
    Die Anfertigung der Konzeption erfolgte stets in enger Zusammenarbeit mit dem Product Owner, bzw dem Praxispartner.
    Hierfür wurden wöchentlich im Meeting die Fortschritte am Projekt dargestellt, sowie die geplanten Vorhaben der kommenden Woche vorgestellt.

    \section{Anforderungen}
    In Rücksprache mit dem Praxispartner, wurden einerseits die Ziele des Systems \textit{DPP} herausgearbeitet.

    Andererseits wurden einzelne Anforderungen konkretisiert, die dazu dienen sollen, das Ziel zu erfüllen.
    Das Hauptziel des Anwendungssystems \textit{DPP} ist die Minimierung von fehlerhaften Schaltanlagen.
    Als Anforderung wurden hierbei eine maximale Fehlerquote von 3\% genannt.

    Um dieser Anforderung gerecht werden zu können, stellt sich der Praxispartner verschiedene Leistungen vor.
    Diese sind einerseits dem Prüfprozess zuordenbar, andererseits soll bereits die Entstehung von Fehlern vermieden
    werden, indem die Monteure während der Produktion unterstützt werden.

    \subsection{Digitale Maschinenakte}\label{subsec:digitale-maschinenakte}
    Zur Verwirklichung des Systems ist es notwendig, die physische Entität des Schaltschranks um eine zusätzliche,
    virtuelle Dimension zu erweitern.
    Diese virtuelle Komponente lässt sich als eine digitale Maschinenakte beschreiben und begleitet das Produkt vom
    Auftragseingang über die Produktion
    bis hin zur Qualitätssicherung.
    Weiter wäre es denkbar, diese auch nach der Auslieferung noch besteht, um Wartungs- und Reparaturvorgänge
    dokumentieren zu können.
    Sie soll dem jeweiligen Schaltschrank über seine Seriennummer eindeutig zuordenbar sein, sodass sie dauerhaft
    aktualisiert werden kann und auch Informationen aus ihr hervorgehen können.
    Beispielsweise soll sie es im Zuge des kontinuierlichen Verbesserungsprozesses ermöglichen, bei einem in der
    Qualitätssicherung erkannten Mangel auf einen vorhergehenden Montageschritt verweisen zu können.
    Einträge der digitalen Maschinenakte, die im Laufe der Produktion und Qualitätssicherung notwendig sind, sind unter
    anderem:
    \begin{itemize}
        \item CAD-Modell des Schaltschranks
        \item Montagepläne
        \item Schaltpläne
        \item Stücklisten
        \item Simulation der zugehörigen Maschine
    \end{itemize}



    \subsection{Kontinierliche technische Prüfung}\label{subsec:kontinierliche-technische-prufung}
    Die erste Leistung ist die \ac{ktP} der Schaltschränke durch Simulation.
    Ziel der \ac{ktP} ist die Auflösung der isolierten Produktion von Schaltschrank und Mechanik.
    Hierbei soll die Maschine, für die die Schaltanlage gebaut wird, durch ein System simuliert werden.
    Der zu produzierende Schaltschrank wird hierzu während der Produktion mit einem Simulationssystem verbunden, dass die Logik der zugehörigen Maschine dauerhaft simuliert.
    Liegt ein technischer Fehler im Schaltschrank vor, würde dieser Fehler direkt im Zuge der Produktion auffallen, bereits vor der Auslieferung auf den Defekt reagiert werden kann.
    Weiter soll das System den derzeitigen Arbeitsfortschritt kennen, um ausschließlich die bisher funktionierenden Baugruppen zu prüfen und folglich realistische Fehlereinschätzungen zu liefern.


    Ein reduzierter Prototyp für Software und Hardware der \ac{ktP} existiert bereits.
    Diese ist bislang jedoch lediglich für eine Version eines Produkts ausgelegt und agiert ohne Kommunikation zu anderen Systemen.
    Die Herausforderung hierbei liegt darin, die \ac{ktP} automatisiert und generisch für jeden Schaltschrank zu ermöglichen.
    Dazu muss die, in der Maschinenakte hinterlegte Simulation durch das System selbstständig aktualisiert werden.
    Da für diese die Logik der Schaltpläne notwendig ist, werden Schnittstellen zu dem Schaltplan-CAD-System benötigt.
    Eine Rücksprache mit dem Unternehmen EPLAN hat zu Beginn des Projektes stattgefunden.
    Dieses sicherte zu, zum Zwecke der Umsetzung der Schnittstellen bestmöglich zu unterstützen.

    %TODO Simulation erklären
    
    \subsection{Visuelle Prüfung}\label{subsec:visuelle-prufung}
    Die visuelle Prüfung soll durch kameragestützte Sensorik erfolgen.
    In der Qualitätssicherung soll dabei lediglich ein oder mehrere Fotos des jeweiligen Schaltschranks gemacht werden, die in das System geladen werden.
    Das System soll das Bild / die Bilder darauffolgend verarbeiten und auf mehrere Gesichtspunkte prüfen.
    Gesichtspunkte die vom Product Owner aufgezählt wurden sind
    \begin{itemize}
        \item Verfügbarkeit der Bauteile: Die Bauteile / Baugruppen, die auf der Stückliste des Schaltplans oder
         CAD-Modells aufgezählt sind, müssen im Schaltschrank verbaut sein
        \item Richtige Position der Bauteile: Die Einbauposition der jeweiligen Bauteile / Baugruppen müssen stets an
        der dafür vorgesehenen Position im Schaltschrank verbaut sein
        \item Optische Beschädigungen: Optische Beschädigungen am Äußeren des Schaltschranks dürfen nicht vorhanden sein
    \end{itemize}


    \subsection{Fehlerfreies Arbeiten}\label{subsec:fehlerfreies-arbeiten}
    Die Funktion \textit{Fehlerfreies Arbeiten} ist in dem Kontext nicht direkt der Qualitätssicherung zuzuweisen.
    Ihr Ziel ist es, den laufenden Produktionsprozess dahingehend zu unterstützen, dass Fehler in der Montage von
    Beginn an vermieden werden.
    Dies soll erreicht werden, indem im Produktionsprozess Technologien eingesetzt werden, die den Monteur schrittweise
    durch die Produktion begleiten und ihm Anweisungen zur Montage der Bauteile / Baugruppen geben.
    Vom Product Owner wurde hier beispielsweise der Einsatz von AR-Brillen genannt, die dem Monteur bei seiner Arbeit
    die vorgesehene Position eines Bauteils einblendet, bzw. das Bauteil an der vorgesehenen Position visuell simuliert.
    Als weitere Technologie wurde Cobotik genannt.
    Ein Anwendungsbeispiel hierfür könnte das automatische Ablängen der Kabelkanäle oder Hutschienen sein.
    Außerdem ist eine häufige Fehlerquelle das falsche Anzugsdrehmoment von Schrauben im Schaltschrank.
    Dem kann durch elektronische Drehmomentschlüssel mit voreingestelltem Drehmoment vorgesorgt werden.


    \section{Architektur von DPP}
    Nach Betrachtung der Anforderungen ist erkennbar, dass die drei Funktionen \textit{Kontinuierliche Technische
    Prüfung}, \textit{Visuelle Prüfung} und \textit{Fehlerfreies Arbeiten} prinzipiell unabhängig voneinander interagieren.
    Allesamt benötigen sie lediglich die Daten der digitalen Maschinenakte.
    Da keine paarweise Assoziation zwischen den Funktionen notwendig ist, würde es sich anbieten, sie als autarke Services
    bereitzustellen.
    Diese müssten dann lediglich zum Erhalt der Daten mit der digitalen Maschinenakte und zur Integration in den
    Fertigungsprozess mit dem Client gekoppelt werden.
    \todo{Fertigstellen Sect ArchDPP}


    \chapter{Implementierung \textit{Visuelle Prüfung}}
    Die Umsetzung des Moduls \textit{Visuelle Prüfung} erfolgte in mehreren Schritten.
    \section{Machbarkeitsanalyse}
    Als ersten Schritt wurde hierfür eine grobe Machbarkeitsanalyse durchgeführt, anhand der ermittelt werden sollte,
    ob die visuelle Identifizierung der Bauteile ohne bauliche Ergänzungen, wie QR- / Bar-Codes auf den Komponenten erfolgen kann.
    Dazu wurde primär Literatur-Recherche betrieben.
    Die Recherche fächerte sich dabei auf in wissenschaftliche Arbeiten, die sich mit der automatisierten Identifikation von Bildinhalten beschäftigen.
    Beispiele hierfür sind die Identifikation von Unterschriften~\cite{Munich2003} oder andere, untergeordnete Komponenten, wie Schrauben~\cite{Lehr2019}.
    \section{Einarbeitung}
    Nachdem festgestellt werden konnte, dass die Objekterkennung und Identifikation von augenscheinlich ähnlichen Objekten möglich ist, wurde sich in die Bildverarbeitungstools eingearbeitet.
    Durch den Praxispartner konnten hierbei Libraries wie OpenCV, oder Pillow genannt werden.
    Diese verfügen zu der umfangreichen Funktionspalette eine vollständige Dokumentation, die bei der Umsetzung unterstützt (/todo{Opencv-Seite anfügen}).

    In der Einarbeitung in die Tools konnte auf verschiedene Ansätze gestoßen werden, auf die im Folgenden eingegangen wird.
    \subsection{Template Matching}
    Der erste Ansatz, der verfolgt wurde, war das Template-Matching.
    Dieses hat das Ziel einen Bild in einem anderen Bild zu finden und zurückzugeben.\cite{CV2TemplateMatching2022}
    Die Attraktivität des Ansatzes ergibt sich aus dem Umfang der Implementierung, die in weniger als 20 Zeilen umsetzen lässt.
    Jedoch muss für ein positives Ergebnis das Request-Bild zwingend eine Teilmenge des Hauptbildes sein, wobei sich maximal die Pixeldichte der Bilder unterscheiden darf.
    Da dies ein eindeutiges Ausschlusskriterium darstellt, wurde die Weiterverfolgung des Ansatzes für die Umsetzung von DPP-Visual früh eingestellt.

    \subsection{Feature-Matching}
    Das Feature-Matching stellte hierbei eine vielversprechendere Variante für die Objekterkennung elektronischer Komponenten dar.
    Dieses Beschreibt den Vorgang, dass anhand eines ausgewählten Algorithmus markante Punkte (= Key-Points) in einem Bild erhoben werden.
    Zu jedem Key-Point wird anschließend eine Beschreibung in Hinblick auf die Daten seiner umliegenden Pixel erstellt.
    Diese Beschreibung ermöglicht den Vergleich zweier Bilder, indem die Key-Point auf Ähnlichkeiten geprüft werden.\cite{CV2FeatureMathing2022}

    Sowohl für den Prozess der Analyse der Key-Points im Bild, als auch der Ähnlichkeitsvergleich (= Matching) der zwischen Request-Bild und der Vorlage
    existieren verschiedene Algorithmen, die einen Einfluss auf die Ergebnismenge haben.
    Bei der Analyse der Key-Points stehen unter anderem die Algorithmen
    \begin{itemize}
        \item SIFT
        \item SURF
        \item ORB
    \end{itemize}
    zur Verfügung.
    Die verschiedenen Algorithmen unterscheiden sich einerseits in ihrer Komplexität und damit auch in ihrer Geschwindigkeit, sowie in dem Umfang ihrer Ergebnismenge.
    Einen Überblick über die Vor- und Nachteile liefern \citet{Karami2017}.
    Zudem wurde die Auswahl empirisch getestet, indem eine Teilmenge der Algorithmen umgesetzt und ihr Ergebnis mit einem Test-Datensatz überprüft wurden.
    Während der ORB-Algorithmus die Key-Points am schnellsten analysierte, gab dieser lediglich die Hälfte der Key-Points des SIFT-Algorithmus zurück.
    Dahingegen war der SURF-Algorithmus langsamer, als der SIFT und lieferte eine vergleichbare Menge an Key-Points zurück.
    Da die Durchlaufzeit der Anwendung eine geringere Priorität als die Zuverlässigkeit der Erkennung besitzt, fiel die Entscheidung auf den SIFT-Algorithmus.

    Das Matching hat die Aufgabe, die Descriptor zweiter Key-Points miteinander zu vergleichen und festzustellen, ob sie Ähnlich zueinander sind.
    Hierbei gibt es ebenso mehrere Ansätze, von denen vor allem zwei in der Dokumentation von OpenCV vertreten sind:
    \begin{itemize}
        \item BruteForce
        \item FlannBased
    \end{itemize}

    Das BruteForce-Verfahren ermittelt hierbei die $L_{2}$-Norm von jedem Key-Point zu jedem Key-Point, wodurch sich die Menge der Rechenschritte durch die Funktion
\begin{center}
    $f(x) = n * m,$ \\
    $wobei~n= Menge~der~ermittelten~Keypoints~im~Requestbild;$\\
    $m = Menge~der~Key-Points~im~Template-Bild$\\
\end{center}
    beschreiben lässt.
    Die Komplexitätsstufe nach Landau-Notation beträgt im worst case folglich näherungsweise $O(n^{2})$.

    Einen weniger komplexen Ansatz soll hierbei der FlannBased-Matching-Algorithmus liefern.
    Im Flann Algorithmus soll der \textit{approximate nearest neighbor} ermittelt werden, der nicht zwangsläufig der nächste Nachbar (entspricht dem Punkt mit der größten Ähnlichkeit) sein muss,
    ihm jedoch sehr nahekommt.
    Zur Ermittlung des \textit{aproximate nearest neighbors} wird der Datensatz in einen KD-Tree überführt, der es erlaubt, dass sich die Menge der zu vergleichenden Key-Points sich auf ein KD-Tree-Feld begrenzt.
    Unter der Annahme einer gleichmäßigen Verteilung aller Punkte über die KD-Tree-Felder würde die sich die Anzahl der Rechenschritte somit auf
    \begin{center}
        $f(x) = (m*n) / k, $ \\
        $wobei~n= Menge~der~ermittelten~Keypoints~im~Requestbild;$\\
        $m = Menge~der~Key-Points~im~Template-Bild$\\
        $k = Menge~der~KD-Tree-Felder$\\
    \end{center}
    begrenzen.

    In einem direkten Vergleich mit einem Beispieldatensatz konnte festgestellt werden, dass der FlannBased-Matcher nahezu identische Ergebnisse wie der BruteForce-Matcher liefert.
    In Kombination mit der Ersparnis von Rechenleistung fiel die Entscheidung somit auf den FlannBased-Matcher.\\



    Der Rückgabewert der Methoden, die die generierten Key-Points matchen beinhaltet einen Array von Positionen, die darstellen, wo in dem Request-Bild Übereinstimmungen mit dem Vorlage-Bild gefunden werden konnten.
    Da diese Übereinstimmungen auch fehlerhafte Werte beinhalten, die sich über das ganze Bild verstreuen können, musste im darauffolgenden Schritt eine Methode erarbeitet werden, um Fehlerdaten zu erkennen.
    \todo{Bild der Keypoints einfügen}

    Bei Betrachtung der Verteilung der Matching-Positionen im Request-Bild lässt sich erkennen, dass sich die Punkte nicht gleichermaßen über das Bild verteilen, sondern sich meist ein Punkt-Zentrum mit höherer Punkte-Konzentration bildet.
    Beim Abgleich dieses Zentrums mit dem Request-Bild kann festgestellt werden, dass sich das gesuchte Objekt meistens in dem ermittelten Zentrum befindet.
    Die Punkte, die außerhalb des Zentrums liegen, sind somit fehlerhafte Daten oder Ausreißer.
    Zur generischen Ermittlung der Ausreißer (= Outlier) wurden verschiedene Ansätze erarbeitet.

    \subsection{Bereinigtes KMeans-Cluster}
    Zu Beginn wurde für die Ermittlung des Punktezentrums und die Ausreißer ein Clustering des Datensatzes mittels KMeans durchgeführt.
    Da KMeans jeden Punkt des Datensatzes einem Cluster zuordnet, werden auch Outlier, die ggf. fehlerhaft sind in das Cluster aufgenommen,
    sofern ihre euklidische Distanz zum Cluster-Schwerpunkts (= Centroid) des korrekten Clusters geringer ist, als die zu den restlichen Clustern.
    Das Ergebnis ist, dass es zum einen mehrere Cluster gibt, die im weiteren Verlauf als gesuchten Bildausschnitt gewertet werden können.
    Zum anderen bewirken Datenpunkte, die stark von ihrem Cluster-Centroid abweichen, dass sich die Außenkanten des Bildausschnitts nach außen hin ausweiten.
    Eine Überlegung zur Beseitigung dieser Datenpunkte war die Minimierung des Clusters auf seine Standardabweichung.
    Hierzu wurde die Standardabweichung in beiden Dimensionen ermittelt, wodurch sich ein Kreis mit dem Radius $\sigma$ um den Centroid des Clusters bildete.
    Im folgenden Schritt wurden alle Punkte, die Element des Clusters sind und sich außerhalb dieses Kreises befinden eliminiert.

    Aus diesem Ansatz heraus ergaben sich zwei Fragen:
    \begin{itemize}
        \item Welches der k Cluster repräsentiert den korrekten Bildausschnitt?
        \item Welcher ist der korrekte Schwellenwert, um Outlier zu definieren?
    \end{itemize}

    Für die Frage des Outlier-Schwellenwerts können alternative Ansätze hierbei verfolgt werden.
    Als Beispiele kann die \textit{Depth-Based Outlier detection} oder die \textit{Extreme Value Analysis} genannt werden, die zielführendere Ergebnisse als die Ermittlung per Standardabweichung liefern können.
    Dennoch bleibt dann weiterhin die Frage, welches der Cluster den gesuchten Bildausschnitt korrekt repräsentiert.
    Weder das Cluster mit der größten Datenpunkt-Dichte, noch das Cluster mit der größten Datenpunkt-Anzahl kann in jedem Fall eindeutig das Bild identifizieren.

    Ein weiterer Ansatz, der kurze Zeit verfolgt wurde, war die Identifizierung über Farbhistogramme.
    Hierbei wurden Farbhistogramme aller geclusterten Bildausschnitte, sowie dem Template-Bild erstellt.
    Farbhistogramme stellen die Verteilung der Graustufen-Werte anhand eines 2D-Graphen dar.
    Dabei repräsentiert die x-Achse die Graustufe (Wert zwischen 0 und 255), und die y-Achse die Anzahl an Pixeln, die diesen Farbwert besitzen.

    Die Farbhistogramme der geclusterten Bildausschnitte wurden im Anschluss auf Ähnlichkeit mit dem Farbhistogramm des Template-Bilds verglichen.
    Die Ermittlung der Ähnlichkeit erfolgte mittels vierer Algorithmen (Korrelation, Chi-Quadrat, Intersection und Hellinger) die im Anschluss miteinander korreliert wurden.
    Als korrekter Bildausschnitt wurde derjenige identifiziert, dessen Ähnlichkeit am höchsten war.

    Das Ergebnis des Farbhistogramm-Ansatzes wurde mittels eines Test-Datensatzes geprüft.
    Dabei wurden hohe Fehlerquoten festgestellt.
    Es ließ sich daraus schließen, dass die Identifizierung des korrekten Clusters über KMeans nicht ohne Weiteres möglich ist.
    Aus diesem Grund wurde im weiteren Verlauf auf einen alternativen Clustering-Algorithmus umgestiegen.

    \subsection{DBSCAN}\label{subsec:dbscan}
    Der \textit{DBSCAN} Clustering-Algorithmus hat im Vergleich zu Algorithmen wie KMeans entscheidende Unterschiede, die für die Umsetzung der Objekterkennung vorteilhaft sind.
    Einer der wichtigsten Vorteile ist hierbei die Basis der Cluster-Ermittlung.
    Diese geschieht in DBSCAN über die Dichte des Clusters, anstatt über die euklidische Distanz zum Centroid.
    Konkreter wird, ein Datenpunkt dem Cluster seines nächsten Nachbarn zugerechnet.
    Die Zurechnung erfolgt jedoch nur dann, wenn die Konditionen der Übergabeparameter erfüllt sind.

    Als eine dieser Konditionen gilt der Parameter \textit{min-pts}, die Toleranz für Rauschen beschreibt.
    Rauschen tritt dann auf, wenn zu wenig Datenpunkte vorhanden sind, um ein eigenes Cluster zu bilden.
    Diese Rauschwerte sollen folglich als Outlier markiert werden.

    Der Übergabeparameter \textit{eps} dahingegen beschreibt die maximale Distanz zu seinem nächsten Nachbarn, bis ein Datenpunkt als Outlier bezeichnet wird.
    \autoref{tab:matrix-dbscan} zeigt die Auswirkung der Wahl der Übergabeparameter auf das Clustering-Ergebnis bei DBScan.
    \begin{table}[h]
        \centering
        \begin{tabular}{c | c | c}
            & eps groß & eps klein \\ \hline
            min-pts groß & wenige sehr große Cluster & große Anzahl an Outlier\\ \hline
            min-pts klein & viele kleine Cluster, kaum Outlier & viele kleine Cluster, wenig Outlier
        \end{tabular}
        \caption{Auswirkungen der Parameter-Wahl \textit{min-pts} und \textit{eps} auf DBSCAN-Cluster}
        \label{tab:matrix-dbscan}
    \end{table}

    Auf die Wahl der Parameter wird in \autoref{sec:umsetzung} weiter eingegangen.

    Wie die Funktionsweise von DBSCAN zeigt, ist die Zahl der Cluster im Gegensatz zu den meisten anderen Cluster-Algorithmen variabel.
    Diese Eigenschaft ist für die Implementierung der Objekterkennung dahingehend vorteilhaft, dass keine Cluster \glqq erzwungen\grqq{} werden.
    Sollte ein gesuchtes Objekt in dem Requestbild nicht vorhanden sein, würde das Clustering alle Datenpunkte als Rauschen oder Outlier kennzeichnen, wodurch kein Cluster entstünde.

    Anhand eines Test-Datensatzes wurde versucht, diese Vorteile in der Praxis zu bestätigen.
    Nachdem das Clustering des Test-Datensatzes durchwegs positiv war, wurde sich auf den DBSCAN-Algorithmus für das Clustering entschieden.

    \subsection{Haar-Cascade-Ansatz}
    \todo{ggf. Ausformulieren}
    
    \section{Konzeption}
    \subsection{Programmiersprache}
    Im Zuge der Implementierung des Moduls DPP Visual werden zahlreiche Methoden der Bildverarbeitung und des
    Computer-Visions benötigt.
    Zudem werden Algorithmen zum Umgang mit großen Datenmengen, wie Clustering verwendet.
    Eine weitere Anforderung für den weiteren Verlauf ist die Unterstützung der Intel RealSense SDK, die benötigt wird,
    um Aufnahmen der 3D-Kamera zu verarbeiten.

    Eine Programmiersprache die diese Anforderungen allesamt erfüllt ist Python.
    Diese bietet neben der Unterstützung der Intel RealSense SDK zahlreiche Libraries wie OpenCV, Numpy, Pandas,
    Pillow etc., die bei der Lösung von Problemen in der Mathematik sowie der Computer-Vision unterstützen.

    Diese Libraries können mit vergleichsweise geringem Aufwand über den Pip-Installer in die Anwendung integriert
    werden, sodass der Funktionsumfang deutlich erweitert werden kann.

    Für die Umsetzung der Testumgebung wurde zusätzlich das pythonbasierte Framework \textit{Flask} mit der
    Template-Engine \textit{Jinja} herangezogen.
    Diese Kombination ermöglicht es eine webbasierte Oberfläche umzusetzen, die das Testen mit einem mobilen Endgerät
    (Tablet, Smartphone) ermöglicht und somit die simultane Überprüfung der Anwendungsergebnisse vereinfacht.

    \subsection{Entwurfsmuster}\label{subsec:entwurfsmuster}
    \todo{Factory Pattern ?}

    \subsection{Aufbau des Tools} \label{subsec:aufbau-des-tools}
    Der Aufbau des Tools erfolgte nach dem bereits vorgestellten Factory-Pattern. 
    Unter Vernachlässigung der App-Factory Klassen und Methoden gliederte sich der Aufbau in die View und das Backend.
    Bei der Implementierung der View wurden zum einen die tatsächliche Benutzeroberfläche in der Auszeichnungssprache
    HTML mit der Template-Engine \textit{Jinja} und JavaScript erstellt.
    Diese war für die Entgegennahme der Benutzerinteraktionen und die Darstellung der Inhalte verantwortlich.
    Zum anderen wurde zusätzlich eine View-Model-Schicht hinzugenommen, die als harmonisierende Schicht zwischen
    Frontend und Backend zuständig ist.
    Diese Schicht wurde in Python-Flask realisiert, das es ermöglicht über Flask-charakteristische Decorator wie
    \textit{@app.route} URLs zur Verfügung zu stellen, über die Methoden aufgerufen werden können.

    Im Backend wurde dahingegen die Logik der Objekterkennung, sowie die Schnittstellen zur virtuellen Maschinenakte realisiert.
    Das Logik-Element teilt sich auf in die Clustering-Logik und die Computer-Vision-Logik, für die jeweils eigene
    Skripte angelegt wurden, die aus dem View-Model heraus erreichbar sind.

    Eine visuelle Darstellung der Skripte mit den wesentlichen Methoden ist der nachstehenden
    \todo{UML Anlegen, UML Einbinden} Abbildung zu entnehmen.
    
    \section{Umsetzung}
    Im folgenden Kapitel wird die Umsetzung des Moduls \textit{DPP Visual} beschrieben.
    Dabei wird vor allem auf die Logik und Routine der Objekterkennung eingegangen.
    Diese ergibt sich, wie in \autoref{subsec:aufbau-des-tools} dargestellt aus den zwei Skripten, \textit{object\_detector.py} und \textit{cluster\_handler.py}.

    \subsection{Skript object\_detector.py}
    Das Skript \textit{object\_detector.py} beinhaltet die gesamte Logik der Objekterkennung mit Ausnahme des Clusterings.
    Die Ausführung des Skripts \textit{object\_detector.py} geschieht, nachdem über die Benutzerschnittstelle das Request-Bild zusammen mit der Seriennummer des zu prüfenden Schaltschranks eingegeben wurde und die Daten zum Schaltschrank aus der digitalen Maschinenakte gelesen wurden.
    Dabei wird das Skript für jede verfügbare, zu testende Komponente im Schaltschrank einmal ausgeführt.
    Zur Erkennung eines Objects wird die Methode \textit{detect\_object(image, template\_collection)} aufgerufen, die als Übergabeparameter sowohl das Request-Bild, als auch einen Array von Vorlage-Bildern enthält.
    Im ersten Teil der Methode werden die Bilder zu einem, für OpenCV verständlichen Format verändert.
    Im Anschluss erfolgt das Ermitteln der Key-Points, indem sowohl das Request-Bild, als auch die Vorlage-Bilder in die Methode \textit{SIFT\_detector()} übergeben werden.
    Die Rückgabe der Methode beinhaltet sowohl eine Sammlung von Key-Points des Request-Bilds, als auch einen Array der für jeden Eintrag die Key-Points eines Vorlage-Bilds enthält.

    Diese beiden Rückgabewerte werden darauffolgend in die Matching-Methode \textit{flann\_matcher()} übergeben, die alle Matching-Positionen im Request-Bild zurückgibt (Vgl. \autoref{flann_matcher}).
    Die erhaltenen Matching-Positionen werden im nächsten Schritt im separierten Skript \textit{cluster\_handler.py} in Cluster überführt.

    Nachdem die Cluster ermittelt wurden, wird das Cluster mit den meisten Datenpunkten ausgewählt und die linke obere, sowie die rechte untere Ecke als Position im Bild zurückgegeben.


    \subsubsection{Key-Detector und -Matcher}
    Ein Kernelement, der eben dargestellten Objekterkennungsroutine ist das Ermitteln und Matchen der Key-Points im Bild.
    Bei diesem Prozess wurde für das Ermitteln der Key-Points der SIFT-Algorithmus und für das Matchen der FLANN-based Matcher gewählt.
    Beim Ermitteln der Key-Points und der Beschreibungen wird dazu für jedes Bild die Methode \textit{detectAndCompute()} aufgerufen, die als Übergabeparameter, das Bild und die Konfiguration des Detection-Algorithmus erhält.
    Für die Konfiguration wurde in der Umsetzung None als Default-Parameter übergeben.
    Die ermittelten Key-Points und ihre Beschreibungen für jedes Bild werden als Tupel in einem Array abgelegt und schließlich zurückgegeben.
    Der SIFT-Algorithmus agiert dabei vollends deterministisch.

    Der FLANN-based Matcher erhält nach Vollendung der Key-Point-Ermittlung alle Key-Points und Beschreibungen und vergleicht die einzelnen Vorlage-Key-Points mit denen des Request-Bilds.
    Dabei wird über die einzelnen Bilder (repräsentiert durch die Key-Points und Beschreibungen) iteriert und für jeden Durchlauf nach Ähnlichkeit zu den Key-Points des Request-Bilds gesucht.
    Die Ähnlichkeit wird dabei als $L_{2}$-Norm dargestellt.
    Ein tatsächliches Matching liegt folglich nur vor, wenn gilt $l_{2} > x,~wobei~x~\epsilon~[0; 1]$.
    Eine Ähnlichkeit von 1 würde dabei einer vollkommenen Übereinstimmung entsprechen.

    In der Umsetzung des Tools wurde für die notwendige Ähnlichkeit 0,6 gewählt.
    Die Ermittlung des Werts gelang durch die Analyse der Verteilung der Ähnlichkeiten.
    Die Wahl eines Werts über 0,6 verringerte die Anzahl der Matches dabei um circa 50 \%, wodurch die Wahrscheinlichkeit erhöht wird, dass kein Cluster gebildet werden kann.
    Bei der Wahl eines Werts unter 0,6 stieg wiederum die Fehlerquote massiv an, wodurch die Eliminierung der Outlier und des Rauschens im Cluster erschwert wurde.

    Das Ergebnis des Key-Matchers ist ein Array mit Positionen, die darstellen, an welchen Positionen im Bild Übereinstimmungen gefunden werden konnten.
    Diese Positionen werden im Anschluss im Clustering analysiert

    \subsubsection{Clustering} \label{subsubsec:clustering}
    Das Clustering ist das zweite Kernelement der Objekterkennung.
    Dieses hat die Aufgabe, die einzelnen Datenpunkte, die Matches darstellen zu gruppieren und anhand dessen die Bauteilränder im Request-Bild zu ermitteln.
    Dazu werden alle Positionen die im Request-Bild als Match identifiziert werden konnten als (x, y)-Tupel dargestellt und über den DBSCAN-Algorithmus geclustert.
    Der Clustering-Algorithmus DBSCAN erhält dafür, wie in \autoref{subsec:dbscan} dargestellt die zwei Übergabeparameter \textit{eps} und \textit{min\_samples}.
    Die Ermittlung der beiden Werte erfolgte in einem iterativen Prozess.
    Dabei wurden ein kleiner Wert für \textit{min\_samples} gewählt (hier: $len(matches) / 10 $) und anhand eines Test-Datensatzes die euklidische Distanz jedes Punktes zu seinem nächsten Nachbarn ermittelt.
    Nach der aufsteigender Sortierung der Distanzen und Zeichnung des Graphen bildet sich eine Abwandlung der Exponential-Funktion mit diskreten Werten.
    Der optimale Wert für Epsilon ist dem y-Wert zu entnehmen, an dem der Graph eine gravierende Steigungsänderung besitzt.\citep{Maklin2019}
    Im nächsten Schritt wurde \textit{min\_samples} erhöht und die Zuverlässigkeit des Clusterings beurteilt.
    Diese Schritte wurden wiederholt, bis das Clustering das korrekte Ergebnis lieferte.
    Unter der Konfiguration $eps = 180; ~ min\_samples=len(matches) / 4$ lieferte der DBSCAN-Algorithmus für den Test-Datensatz die korrekten Outlier, womit der Konfigurationsprozess abgeschlossen war.

    Nachdem die Outlier und Rauschdaten eliminiert werden konnten, bleiben letztlich nur die Werte, die das gesuchte Bauteil repräsentieren.
    Diese werden folglich zurückgegeben.


    \chapter{Evaluation}
    Im Zuge der Evaluation sollte die Funktionsweise des entwickelten Systems bewertet werden.
    Hierbei handelt es sich sowohl um die digitalen Maschinenakte, als auch auf das Modul \textit{DPP Visual}.
    Aufgrund der Größe des Projekts und der entsprechend kurzen Zeit des Praktikums erfolgte die Evaluation nur im begrenzten Rahmen.
    Dabei wurde das Modul \textit{DPP Visual} auf die allgemeine Funktionsweise geprüft, sowie auf die Grenzen des Systems und die Dauer des Prüfverfahrens.
    Da das Modul \textit{DPP Visual} die Funktionsweise digitale Maschinenakte mit einschließt, und diese wenig kritische Elemente besitzt, wurde sich bei der Evaluation auf \textit{DPP Visual} beschränkt.

    Das entwickelte Tool wurde auf dem Python3-Development-Server gehostet.
    Dieser lief auf einem Mac Mini mit 3,2 GHz 6-Core Intel Core i7 und 16 GB DDR4 RAM.

    Für die Evaluation wurde in die digitale Maschinenakte der elektronische Schaltplan eines PH-Cell-Schaltschranks eingepflegt.
    Dieser enthält die Stückliste, die alle Komponenten beinhaltet.
    Davon wurden vier Komponenten ausgewählt, für die jeweils 9 bis 17 Bilder der jeweiligen Komponente in die digitale Maschinenakte hinzugefügt wurden (insgesamt 57 Bilder).
    Die kleinste Komponente besitzt dabei eine Größe von 2 x 8 x 8, die größte Komponente 10 x 10 x 10 (Breite x Höhe x Tiefe jeweils in Centimeter)\todo{Bilder der Komponenten einfügen}.

    Als Nächstes wurde eine Bestellung simuliert, indem eine PH-Cell-Schaltschrank-Instanz im System aufgenommen wurde.

    Zur Prüfung der Funktionsweise und der Grenzen der Objekterkennung wurden mehrere Bilder, von korrekt aufgebauten Schaltschränken als Request-Bilder verwendet.
    Diese wurden mit der Kamera eines Apple iPhone 12s unter guter Belichtung aufgenommen.
    Zur Prüfung der allgemeinen Funktionsweise war die Perspektive der Bilder komplett frontal (10 Bilder).
    Im nächsten Schritt erfolgten die Aufnahmen aus verschiedenen Winkeln bis hin zu + / - 45° (5 Bilder aus positivem, 5 Bilder aus negativem Winkel).
    Weiter wurden Aufnahmen des Schaltschranks gemacht, auf denen einzelne Komponenten nicht vorhanden bzw. zu sehen waren (4 Bilder).

    Zuerst wurden die Frontalaufnahmen zusammen mit der Seriennummer jeweils in die Eingabemaske eingegeben und die Prüfung gestartet.
    Im nächsten Schritt wurde schrittweise der Winkel zum Schaltschrank erhöht.
    Als letztes Testszenario wurden die Aufnahmen verwendet, auf denen Komponenten fehlen.

    \section{Ergebnis}
    Das Ergebnis der Evaluation zeigte, dass das Tool grundlegend funktioniert.
    Vor allem bei den Frontalaufnahmen wurden mit wenigen Ausnahmen alle gesuchten Komponenten erkannt.
    Die Markierung auf den Bildern stimmten dabei jedoch nicht immer mit den Außenkanten der Komponenten überein.
    Bei den Frontalaufnahmen mit fehlenden Komponenten wurde mit einer Ausnahme immer auf das Fehlen hingewiesen.

    Bei den Aufnahmen aus verschiedenen Winkeln konnte sich das System weniger beweisen.
    Hierbei traten Fehler bereits ab circa + / - 20° auf, sodass teilweise mehrere Komponenten entweder nicht erkannt wurden, oder die Komponenten an falschen Stellen erkannt wurden.

    \textit{False-Negative}-Fälle traten nur in zwei der 25 Tests auf, wohingegen \textit{False-Positiv}-Fälle deutlich häufiger auftraten.
    Dennoch sind die fehlerfreien Durchläufe in den Tests am meisten vertreten.

    Zu bemängeln ist die Durchlaufzeit Objekterkennung.
    Diese beträgt für einen Durchlauf unter den angegebenen Bedingungen zwischen 90 und 180 Sekunden.
    Zurückzuführen ist ein Großteil der Durchlaufzeit auf die Key-Point-Ermittlung mittels SIFT-Algorithmus.
    Für die Ermittlung der Key-Points eines Bildes werden dabei circa 1,5 bis 2 Sekunden benötigt.
    Bei den hier eingesetzten 57 Bildern werden allein durch diesen Prozess bereits 85 bis 114 Sekunden benötigt.
    Der restliche Teil des Algorithmus spielt in der Durchlaufzeit eine untergeordnete Rolle.


    \section{Weiterentwicklung und Reflektion}
    Wie anhand des Testergebnisses zu sehen ist, leistet das Modul \textit{DPP Visual} für den Anfang gute Ergebnisse.
    Innerhalb der bislang umgesetzten Funktionen ist einerseits die Fehleranfälligkeit bei Aufnahmen außerhalb der Frontalperspektive verbesserungswürdig.
    Andererseits müssen auch diverse Optimierungen vorgenommen werden, um die Durchlaufzeit zu minimieren.

    Ebenso im Rahmen der Implementierung wurden Elemente umgesetzt, die für künftige Weiterentwicklungen optimiert werden können.
    Als ein Beispiel ist hierbei die Auswahl des Clusters in der Hauptroutine zu nennen.
    Werden innerhalb der Objekterkennung einer Komponente mehr als ein Cluster erkannt, so wird das Cluster mit den meisten Datenpunkten ausgewählt.
    Dieser Ansatz hat in dem vorliegenden Datensatz zwar funktioniert, kann aber bei einer größeren Menge an Durchläufen gegebenenfalls falsche Ergebnisse liefern.
    \todo{Verbesserung?}




    \begin{itemize}
        \item Hauptroutine: Cluster mit meisten Datenpunkten: Nicht optimal
        \item Key-Detector: Deterministisch --> Keypoints können einmalig generiert und in DB gespeichert werden
        \item Clustering: Ermittlung Epsilon
    \end{itemize}
   \chapter{Fazit}

    \begin{itemize}
        \item Einordnung des Projekts in Themenbereich WINF
        \item Kritisches Betrachten des Ergebnisses
        \item Kritisches Betrachten des Vorgehens
        \item Weiterer Ausblick
        \item Bewertung des Praxispartners
    \end{itemize}




    \bibliography{main}
    \backmatter
    \input{wochenbericht.tex}
    \input{acronym.tex}
    \input{erklaerung-unibw}

\end{document}
